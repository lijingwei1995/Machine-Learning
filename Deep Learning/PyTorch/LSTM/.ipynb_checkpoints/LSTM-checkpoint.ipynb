{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x5d2dfb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {
    "embreber.gif": {
     "image/gif": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed reber文法\n",
    "![embreber.gif](attachment:embreber.gif)\n",
    "识别embed reber文法需要可以记忆长期依赖的模型\n",
    "\n",
    "生成embed reber串可以在之前的生成模块两边随机生成T或P的对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BTBTXXTTVPSETE', 'BPBTXXTTVPSEPE', 'BTBTSSSXXVVETE', 'BTBPVPXTTVVETE', 'BTBTSSXXVPSETE', 'BPBTSXXTTVVEPE', 'BTBPTTVPXVVETE', 'BPBTXXTTVPSEPE', 'BPBTSSSSSXSEPE', 'BTBTSSSXXVVETE', 'BPBPTVPXTVVEPE', 'BPBPVPXTTVVEPE', 'BPBPTTTTVPSEPE', 'BTBTXXTTVPSETE', 'BTBTSSSXXVVETE', 'BPBTSSSXXVVEPE', 'BPBTSSSSSXSEPE', 'BTBPTTTTTVVETE', 'BTBTXXTTVPSETE', 'BPBPVPXTTVVEPE', 'BPBPVPXTTVVEPE', 'BTBTSSXXVPSETE', 'BPBPTTTTVPSEPE', 'BPBPTTVPXVVEPE', 'BPBPTTTTVPSEPE', 'BTBTXXVPXVVETE', 'BPBPVPXTVPSEPE', 'BPBTSXXTVPSEPE', 'BTBTSSXXTVVETE', 'BPBPVPXTVPSEPE', 'BTBTSSXXTVVETE', 'BPBTXXTTTVVEPE', 'BTBTXXTTVPSETE', 'BTBTSXXTTVVETE', 'BTBTSSSXXVVETE', 'BPBPTVPXTVVEPE', 'BTBPTTVPXVVETE', 'BTBTXXTTVPSETE', 'BPBTXXTTTVVEPE', 'BPBPVPXTVPSEPE', 'BPBTXXVPXVVEPE', 'BPBPVPXTVPSEPE', 'BTBPTVPXTVVETE', 'BTBPVPXTVPSETE', 'BTBPTTTTTVVETE', 'BTBTXXTTTVVETE', 'BPBTXXVPXVVEPE', 'BPBTSXXTTVVEPE', 'BPBPVPXTVPSEPE', 'BPBPTTTTVPSEPE', 'BTBPTTTTVPSETE', 'BPBTXXVPXVVEPE', 'BPBTSXXTVPSEPE', 'BPBPTTTTVPSEPE', 'BPBTSSSXXVVEPE', 'BTBTSXXTTVVETE', 'BTBTSSSXXVVETE', 'BTBTSSSXXVVETE', 'BTBTSSSXXVVETE', 'BPBPVPXTVPSEPE', 'BPBPTVPXVPSEPE', 'BTBPTVPXTVVETE', 'BTBTSSSSSXSETE', 'BTBPVPXTVPSETE', 'BPBTXXVPXVVEPE', 'BPBTXXTTVPSEPE', 'BTBTSSXXTVVETE', 'BPBTXXTTVPSEPE', 'BPBTSSSSSXSEPE', 'BTBTSXXTTVVETE', 'BTBPTVPXVPSETE', 'BPBPTTTTTVVEPE', 'BTBTSSSXXVVETE', 'BTBPVPXTTVVETE', 'BPBPTTTTTVVEPE', 'BPBPTVPXVPSEPE', 'BTBTXXTTTVVETE', 'BPBPTTTTTVVEPE', 'BPBPTTVPXVVEPE', 'BPBPVPXTVPSEPE', 'BTBTSSXXTVVETE', 'BTBTXXTTVPSETE', 'BPBTXXTTTVVEPE', 'BTBTSSXXTVVETE', 'BPBTSXXTTVVEPE', 'BPBPTTTTTVVEPE', 'BTBTXXTTVPSETE', 'BTBTSXXTTVVETE', 'BPBPVPXTVPSEPE', 'BPBTSSXXVPSEPE', 'BPBPTVPXVPSEPE', 'BPBTSSXXVPSEPE', 'BTBPTVPXVPSETE', 'BTBPVPXTVPSETE', 'BPBPTTVPXVVEPE', 'BPBPVPXTTVVEPE', 'BTBPTTTTTVVETE', 'BTBTSSSSSXSETE', 'BPBTSSXXVPSEPE', 'BPBPTTVPXVVEPE', 'BTBPVPXTTVVETE', 'BTBTXXTTTVVETE', 'BPBPVPXTTVVEPE', 'BPBPTVPXTVVEPE', 'BTBTSSSSSXSETE', 'BPBTSSXXVPSEPE', 'BTBTXXVPXVVETE', 'BTBPTVPXVPSETE', 'BPBPTTTTTVVEPE', 'BTBPTVPXVPSETE', 'BTBPTTTTTVVETE', 'BTBPVPXTTVVETE', 'BTBPTTTTTVVETE', 'BPBPTVPXVPSEPE', 'BPBTSXXTTVVEPE', 'BTBTXXTTTVVETE', 'BPBPVPXTTVVEPE', 'BTBTXXTTTVVETE', 'BPBTXXTTVPSEPE', 'BPBPTTTTVPSEPE', 'BPBTXXTTTVVEPE', 'BPBTSXXTVPSEPE', 'BTBTSSXXTVVETE', 'BTBPVPXTVPSETE', 'BPBTXXTTTVVEPE', 'BPBTXXTTTVVEPE', 'BPBPVPXTVPSEPE', 'BPBTSSSXXVVEPE', 'BTBTSXXTTVVETE', 'BPBTXXTTTVVEPE', 'BPBTXXTTTVVEPE', 'BPBPTVPXTVVEPE', 'BPBTSXXTVPSEPE', 'BPBPTTTTVPSEPE', 'BPBTXXTTVPSEPE', 'BPBTXXVPXVVEPE', 'BPBPVPXTVPSEPE', 'BPBTXXTTVPSEPE', 'BPBTXXTTVPSEPE', 'BPBPTTTTTVVEPE', 'BTBPTTTTVPSETE', 'BPBPTTTTTVVEPE', 'BPBPTTTTVPSEPE', 'BTBTXXTTVPSETE', 'BPBPTTVPXVVEPE', 'BPBTSSSXXVVEPE', 'BTBPTVPXTVVETE', 'BTBPTTTTVPSETE', 'BTBTXXTTVPSETE', 'BPBTSSXXTVVEPE', 'BTBPTTTTVPSETE', 'BTBPVPXTTVVETE', 'BTBTSSXXVPSETE', 'BTBTXXVPXVVETE', 'BTBTSXXTTVVETE', 'BPBTXXTTVPSEPE', 'BPBTSSXXVPSEPE', 'BPBPTVPXVPSEPE', 'BTBTXXTTTVVETE', 'BPBTSSSXXVVEPE', 'BTBTSSSSSXSETE', 'BTBTSSSSSXSETE', 'BTBTSSXXVPSETE', 'BPBPTTVPXVVEPE', 'BTBTXXTTTVVETE', 'BPBTSSXXTVVEPE', 'BPBPTVPXVPSEPE', 'BTBPTVPXVPSETE', 'BTBPVPXTVPSETE', 'BPBPTTVPXVVEPE', 'BPBTSSSSSXSEPE', 'BPBTXXVPXVVEPE', 'BPBTSSSSSXSEPE', 'BPBPTTTTVPSEPE', 'BTBPVPXTVPSETE', 'BPBTXXTTVPSEPE', 'BTBTSXXTVPSETE', 'BTBPVPXTTVVETE', 'BTBPTTTTTVVETE', 'BPBTXXVPXVVEPE', 'BPBTSSSSSXSEPE', 'BPBTSXXTVPSEPE', 'BPBPTTTTTVVEPE', 'BTBTSSXXVPSETE', 'BTBTSSSSSXSETE', 'BTBTSSSSSXSETE', 'BTBTXXTTTVVETE', 'BTBPTVPXTVVETE', 'BTBTSSSSSXSETE', 'BPBTSSXXVPSEPE', 'BTBTXXTTVPSETE', 'BPBPTTTTVPSEPE', 'BTBPTTVPXVVETE', 'BTBTXXTTVPSETE', 'BTBPTVPXVPSETE', 'BTBPVPXTVPSETE', 'BTBPTTTTVPSETE', 'BPBPTTTTVPSEPE', 'BPBTXXTTTVVEPE', 'BTBPTTTTVPSETE', 'BPBTSSSSSXSEPE', 'BPBPVPXTVPSEPE', 'BPBTXXTTTVVEPE', 'BTBTXXTTTVVETE', 'BTBTXXVPXVVETE', 'BPBPTVPXVPSEPE', 'BTBPVPXTTVVETE', 'BPBPTTVPXVVEPE', 'BPBPVPXTTVVEPE', 'BTBTSSSXXVVETE', 'BTBTSSSSSXSETE', 'BPBPTTTTTVVEPE', 'BPBPVPXTVPSEPE', 'BTBPTVPXTVVETE', 'BPBPVPXTTVVEPE', 'BPBTSXXTTVVEPE', 'BPBPVPXTVPSEPE', 'BPBPVPXTTVVEPE', 'BPBTSSSXXVVEPE', 'BPBTSSSXXVVEPE', 'BTBPTTTTVPSETE', 'BPBPTTTTVPSEPE', 'BTBTSSSXXVVETE', 'BTBPTVPXTVVETE', 'BPBPTTTTVPSEPE', 'BPBTSSXXTVVEPE', 'BTBPTTTTTVVETE', 'BTBTSXXTTVVETE', 'BTBPTVPXVPSETE', 'BPBPVPXTVPSEPE', 'BPBTXXVPXVVEPE', 'BPBTSSSSSXSEPE', 'BTBPTTTTVPSETE', 'BTBPTVPXVPSETE', 'BTBPTTVPXVVETE', 'BTBPTTTTVPSETE', 'BPBPVPXTTVVEPE', 'BTBTSSSXXVVETE', 'BTBPVPXTVPSETE', 'BTBTXXVPXVVETE', 'BTBTSSSXXVVETE', 'BPBPTTTTVPSEPE', 'BPBPVPXTTVVEPE', 'BTBPTVPXVPSETE', 'BPBTSSSXXVVEPE', 'BPBPVPXTTVVEPE', 'BPBTXXTTTVVEPE', 'BTBTXXTTTVVETE', 'BTBTSSSSSXSETE', 'BPBTSSSSSXSEPE', 'BPBTXXVPXVVEPE', 'BPBTXXTTVPSEPE', 'BPBPVPXTVPSEPE', 'BPBPVPXTTVVEPE', 'BPBTSSXXTVVEPE', 'BTBPTVPXVPSETE']\n"
     ]
    }
   ],
   "source": [
    "# 生成embed reber语言\n",
    "def EMBED_REBER(n, lenth=None):\n",
    "    N = 0\n",
    "    R = []\n",
    "    while N < n:\n",
    "        r, s = \"B\", 0 # 初始文字，状态\n",
    "        transfer_map = {\n",
    "            0 : [(\"T\", 1), (\"P\", 2)],\n",
    "            1 : [(\"S\", 1), (\"X\", 3)],\n",
    "            2 : [(\"T\", 2), (\"V\", 4)],\n",
    "            3 : [(\"X\", 2), (\"S\", 5)],\n",
    "            4 : [(\"P\", 3), (\"V\", 5)]\n",
    "        }\n",
    "\n",
    "        while s != 5 :\n",
    "            if np.random.rand() > 0.5:\n",
    "                next_state = transfer_map[s][0]\n",
    "            else:\n",
    "                next_state = transfer_map[s][1]\n",
    "            r += next_state[0]\n",
    "            s = next_state[1]\n",
    "\n",
    "        r += \"E\"\n",
    "        \n",
    "        # 两侧添加\n",
    "        if np.random.rand() > 0.5:\n",
    "            r = \"BT\" + r + \"TE\"\n",
    "        else:\n",
    "            r = \"BP\" + r + \"PE\"\n",
    "        \n",
    "        if lenth:\n",
    "            if len(r) == lenth:\n",
    "                R.append(r)\n",
    "                N += 1\n",
    "        else:\n",
    "            R.append(r)\n",
    "            N += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    return R\n",
    "\n",
    "train_data = EMBED_REBER(256, 14)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0, 'T': 1, 'P': 2, 'S': 3, 'X': 4, 'V': 5, 'E': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list = list(\"BTPSXVE\")\n",
    "char_num  = len(char_list)\n",
    "char_map  = {c : char_list.index(c) for c in char_list}\n",
    "char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]]]), tensor([[2, 2, 1, 2, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [2, 1, 1, 1, 2],\n",
      "        [1, 4, 3, 3, 1],\n",
      "        [1, 4, 3, 3, 1],\n",
      "        [5, 1, 3, 3, 1],\n",
      "        [2, 1, 4, 3, 1],\n",
      "        [4, 5, 4, 3, 5],\n",
      "        [5, 2, 5, 4, 2],\n",
      "        [5, 3, 5, 3, 3],\n",
      "        [6, 6, 6, 6, 6],\n",
      "        [2, 2, 1, 2, 1],\n",
      "        [6, 6, 6, 6, 6]]))\n"
     ]
    }
   ],
   "source": [
    "# 数据生成器，用于读取批量数据\n",
    "# 每个序列的前 L-1 位作为输入，后 L-1个作为监督信号\n",
    "def data_iter(batch_size, data):\n",
    "    # 数据大小\n",
    "    data_num = len(data)\n",
    "    seq_num  = len(data[0])\n",
    "    char_num = 7\n",
    "    # 随机排列\n",
    "    permutation = np.arange(data_num)\n",
    "    np.random.shuffle(permutation)\n",
    "    permutation = permutation.tolist()\n",
    "    # 每次取 batch_size 个\n",
    "    for i in range(0, data_num, batch_size):\n",
    "        # 每个 batch 的下标\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        \n",
    "        # 按照时间顺序变换\n",
    "        batch_n_list = [] # 得到每一个字符对应的数字\n",
    "        batch_n_advisor_list = [] # 监督信号\n",
    "        for j in indices:\n",
    "            # 对batch中下标为j的字符串数字化\n",
    "            n_list = []\n",
    "            for k in data[j]:\n",
    "                # 获取该字符对应的数字\n",
    "                n_list.append(char_map[k])\n",
    "            \n",
    "            batch_n_list.append(n_list[:-1])\n",
    "            batch_n_advisor_list.append(n_list[1:])\n",
    "\n",
    "        # 将其传入one_hot函数，得到(batch*seq*char)的tensor\n",
    "        batch_seq_one_hot = F.one_hot(torch.tensor(batch_n_list), char_num)\n",
    "        \n",
    "        # 改为seq first的tensor，转置前两维\n",
    "        seq_batch_one_hot = batch_seq_one_hot.transpose(0, 1)\n",
    "        \n",
    "        # advisor的tensor(batch*seq*char)\n",
    "        batch_seq_advisor = torch.tensor(batch_n_advisor_list)\n",
    "        seq_batch_advisor = batch_seq_advisor.transpose(0, 1) # 转置\n",
    "        \n",
    "        yield seq_batch_one_hot, seq_batch_advisor\n",
    "    \n",
    "data_iter_ = data_iter(5, train_data)\n",
    "for _ in range(1):\n",
    "    data = next(data_iter_)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReberLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # parameters\n",
    "        char_num = 7\n",
    "        \n",
    "        # layers\n",
    "        self.input_hidden_layer = nn.LSTM(input_size=char_num, hidden_size=10, bias=False)\n",
    "        self.output_layer = nn.Linear(in_features=10, out_features=char_num, bias=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_output, h_n = self.input_hidden_layer(input)\n",
    "        output = self.output_layer(hidden_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epoch          0 , Loss is 1.9548033475875854\n",
      " for epoch       2000 , Loss is 1.8906290531158447\n",
      " for epoch       4000 , Loss is 1.734405755996704\n",
      " for epoch       6000 , Loss is 1.465674877166748\n",
      " for epoch       8000 , Loss is 1.128794550895691\n",
      " for epoch      10000 , Loss is 0.8521116971969604\n",
      " for epoch      12000 , Loss is 0.684528112411499\n",
      " for epoch      14000 , Loss is 0.5828148126602173\n",
      " for epoch      16000 , Loss is 0.5073099732398987\n",
      " for epoch      18000 , Loss is 0.4440280795097351\n",
      " for epoch      20000 , Loss is 0.4292106330394745\n",
      " for epoch      22000 , Loss is 0.40830039978027344\n",
      " for epoch      24000 , Loss is 0.3769316077232361\n",
      " for epoch      26000 , Loss is 0.3645888566970825\n",
      " for epoch      28000 , Loss is 0.3780266046524048\n",
      " for epoch      30000 , Loss is 0.3557244837284088\n",
      " for epoch      32000 , Loss is 0.3334082067012787\n",
      " for epoch      34000 , Loss is 0.34226587414741516\n",
      " for epoch      36000 , Loss is 0.33130741119384766\n",
      " for epoch      38000 , Loss is 0.32906052470207214\n"
     ]
    }
   ],
   "source": [
    "myNN = ReberLSTM()\n",
    "\n",
    "# 训练阶段\n",
    "epoch_num  = 40000\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 生成优化器\n",
    "optimizer = optim.SGD(myNN.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for INPUT, TARGET in data_iter(batch_size, train_data):\n",
    "        # forward\n",
    "        output = myNN(INPUT.float())\n",
    "        Loss = F.cross_entropy(output.reshape(-1, 7), TARGET.reshape(-1))\n",
    "        \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        Loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 2000 == 0:\n",
    "        print(\" for epoch %10d , Loss is %s\" % (epoch, Loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.1752,   5.4207,   5.5639,  -3.7640,  -3.0423,  -1.1156,  -3.6353]],\n",
       "\n",
       "        [[  5.7254,   1.8105,  -0.9432,  -1.4328,   0.0811,  -0.9515,  -3.5621]],\n",
       "\n",
       "        [[ -1.0067,   4.9332,   4.7987,  -0.4179,  -0.5712,  -0.3460,  -7.5094]],\n",
       "\n",
       "        [[  1.5289,  -1.3405,  -1.2662,   5.0093,   4.7933,  -0.1269,  -7.7689]],\n",
       "\n",
       "        [[ -0.8584,   1.5755,  -1.3819,   2.5048,   6.0253,   1.5062,  -8.9626]],\n",
       "\n",
       "        [[ -1.4433,   5.9936,  -0.3196,  -2.2986,   2.7568,   4.8076,  -9.8731]],\n",
       "\n",
       "        [[ -3.2112,   8.3764,   2.3120,  -3.9890,   0.3093,   5.8915, -10.5837]],\n",
       "\n",
       "        [[ -4.8337,   7.0537,   2.1827,  -2.7873,  -0.1197,   6.3740,  -8.8994]],\n",
       "\n",
       "        [[ -9.2790,   1.7478,   9.5693,  -0.9397,  -1.9602,   3.2924,  -3.9688]],\n",
       "\n",
       "        [[ -5.5410,  -3.6882,  -2.6714,   6.3192,   3.0562,   1.5940,   0.9167]],\n",
       "\n",
       "        [[ -4.7384,  -2.5396,   0.7886,   1.1844,  -1.7159,   0.8428,   5.4067]],\n",
       "\n",
       "        [[ -4.9835,   4.5095,   7.1402,  -3.9684,  -5.1194,  -0.3571,   1.7751]],\n",
       "\n",
       "        [[ -1.7598,  -2.8126,  -0.4499,   1.2460,  -1.2755,  -2.3244,   7.6601]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测一个序列\n",
    "seq = 'BPBTXXTTVPSEPE'\n",
    "# 转为 seq_one_hot\n",
    "n_list = []\n",
    "for i in seq:\n",
    "    # 获取该字符对应的数字\n",
    "    n_list.append(char_map[i])\n",
    "seq_one_hot = F.one_hot(torch.tensor(n_list))\n",
    "test_output = myNN(seq_one_hot[:-1].unsqueeze(1).float())\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当输入第二位是P的时候，倒数第二位的输出是P的概率大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1752,  5.4207,  5.5639, -3.7640, -3.0423, -1.1156, -3.6353]],\n",
       "\n",
       "        [[ 5.6729, -0.3451, -2.7417,  0.4560,  1.0183, -1.3840, -1.6948]],\n",
       "\n",
       "        [[-1.3772,  4.6833,  4.5907, -0.4523, -0.5792, -0.3573, -6.6005]],\n",
       "\n",
       "        [[ 1.6300, -1.7902, -2.1118,  5.2278,  4.8419, -0.3009, -6.6145]],\n",
       "\n",
       "        [[ 0.4648, -3.8128, -3.5149,  7.4675,  6.3972, -1.0131, -5.0394]],\n",
       "\n",
       "        [[-0.5773, -4.6519, -4.9228,  8.5415,  7.7752, -0.8830, -4.3560]],\n",
       "\n",
       "        [[-2.4452, -3.3885, -4.2938,  8.1496,  7.8386, -0.7932, -4.4537]],\n",
       "\n",
       "        [[-4.1047,  1.0638, -3.8039,  3.9245,  5.9701,  2.5496, -5.7881]],\n",
       "\n",
       "        [[-7.3254,  2.3843, -2.7041,  2.2312,  1.7926,  6.4075, -3.8856]],\n",
       "\n",
       "        [[-9.6391, -1.0459,  1.6402,  0.4471, -1.7953,  6.7993,  1.5194]],\n",
       "\n",
       "        [[-4.4682, -3.4255,  0.4139,  1.3988, -1.6978, -0.8825,  7.7974]],\n",
       "\n",
       "        [[-2.8598,  5.7088,  4.7404, -4.2420, -3.6867, -0.8134,  0.4342]],\n",
       "\n",
       "        [[-0.0794, -0.2810, -0.3983, -2.0691, -3.1652, -0.8365,  6.7006]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测一个序列\n",
    "seq = 'BTBTSSSXXVVETE'\n",
    "# 转为 seq_one_hot\n",
    "n_list = []\n",
    "for i in seq:\n",
    "    # 获取该字符对应的数字\n",
    "    n_list.append(char_map[i])\n",
    "seq_one_hot = F.one_hot(torch.tensor(n_list))\n",
    "test_output = myNN(seq_one_hot[:-1].unsqueeze(1).float())\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当输入第二位是T的时候，倒数第二位的输出是T的概率大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
